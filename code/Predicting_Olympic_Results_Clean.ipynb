{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting Olympic medals with Deep Learning\n",
        "\n",
        "- It's almost Olympics time, and we're here to predict medals!\n",
        "- Let's start out by installing and importing everything we need:"
      ],
      "metadata": {
        "id": "FPaspaNLbBYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna  > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "F0cPTj3Meoc6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn torch transformers  > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "sPrrXvGATcAC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia-api > /dev/null 2>&1"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ayE0V6MT4erQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import pipeline\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import datetime\n",
        "import wikipediaapi"
      ],
      "metadata": {
        "id": "pIuhIIeaPDUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have a GPU, this is your best friend:"
      ],
      "metadata": {
        "id": "0fe1PBsWbc1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "vbYBXrPpT9KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's hard-code the participating countries. Each country has a 3-letter code called its NOC. It will be super handy today."
      ],
      "metadata": {
        "id": "t45J7HdfbkO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of tuples mapping countries to their NOCs\n",
        "participating_countries = [\n",
        "    # Africa\n",
        "    (\"Algeria\", \"ALG\"),\n",
        "    (\"Angola\", \"ANG\"),\n",
        "    (\"Benin\", \"BEN\"),\n",
        "    (\"Botswana\", \"BOT\"),\n",
        "    (\"Burkina Faso\", \"BUR\"),\n",
        "    (\"Burundi\", \"BDI\"),\n",
        "    (\"Cameroon\", \"CMR\"),\n",
        "    (\"Cabo Verde\", \"CPV\"),\n",
        "    (\"Central African Republic\", \"CAF\"),\n",
        "    (\"Chad\", \"CHA\"),\n",
        "    (\"Comoros\", \"COM\"),\n",
        "    (\"Congo\", \"CGO\"),\n",
        "    (\"Democratic Republic of the Congo\", \"COD\"),\n",
        "    (\"Côte d’Ivoire\", \"CIV\"),\n",
        "    (\"Djibouti\", \"DJI\"),\n",
        "    (\"Egypt\", \"EGY\"),\n",
        "    (\"Eritrea\", \"ERI\"),\n",
        "    (\"Eswatini\", \"SWZ\"),\n",
        "    (\"Ethiopia\", \"ETH\"),\n",
        "    (\"Gabon\", \"GAB\"),\n",
        "    (\"Gambia\", \"GAM\"),\n",
        "    (\"Ghana\", \"GHA\"),\n",
        "    (\"Guinea\", \"GUI\"),\n",
        "    (\"Guinea-Bissau\", \"GBS\"),\n",
        "    (\"Equatorial Guinea\", \"GEQ\"),\n",
        "    (\"Kenya\", \"KEN\"),\n",
        "    (\"Lesotho\", \"LES\"),\n",
        "    (\"Liberia\", \"LBR\"),\n",
        "    (\"Libya\", \"LBA\"),\n",
        "    (\"Madagascar\", \"MAD\"),\n",
        "    (\"Malawi\", \"MAW\"),\n",
        "    (\"Mali\", \"MLI\"),\n",
        "    (\"Morocco\", \"MAR\"),\n",
        "    (\"Mauritius\", \"MRI\"),\n",
        "    (\"Mauritania\", \"MTN\"),\n",
        "    (\"Mozambique\", \"MOZ\"),\n",
        "    (\"Namibia\", \"NAM\"),\n",
        "    (\"Niger\", \"NIG\"),\n",
        "    (\"Nigeria\", \"NGR\"),\n",
        "    (\"Uganda\", \"UGA\"),\n",
        "    (\"Rwanda\", \"RWA\"),\n",
        "    (\"Sao Tome and Principe\", \"STP\"),\n",
        "    (\"Senegal\", \"SEN\"),\n",
        "    (\"Seychelles\", \"SEY\"),\n",
        "    (\"Sierra Leone\", \"SLE\"),\n",
        "    (\"Somalia\", \"SOM\"),\n",
        "    (\"South Africa\", \"RSA\"),\n",
        "    (\"South Sudan\", \"SSD\"),\n",
        "    (\"Sudan\", \"SUD\"),\n",
        "    (\"United Republic of Tanzania\", \"TAN\"),\n",
        "    (\"Togo\", \"TOG\"),\n",
        "    (\"Tunisia\", \"TUN\"),\n",
        "    (\"Zambia\", \"ZAM\"),\n",
        "    (\"Zimbabwe\", \"ZIM\"),\n",
        "\n",
        "    # The Americas\n",
        "    (\"Antigua and Barbuda\", \"ANT\"),\n",
        "    (\"Argentina\", \"ARG\"),\n",
        "    (\"Aruba\", \"ARU\"),\n",
        "    (\"Bahamas\", \"BAH\"),\n",
        "    (\"Barbados\", \"BAR\"),\n",
        "    (\"Belize\", \"BIZ\"),\n",
        "    (\"Bermuda\", \"BER\"),\n",
        "    (\"Bolivia\", \"BOL\"),\n",
        "    (\"Brazil\", \"BRA\"),\n",
        "    (\"Cayman Islands\", \"CAY\"),\n",
        "    (\"Canada\", \"CAN\"),\n",
        "    (\"Chile\", \"CHI\"),\n",
        "    (\"Colombia\", \"COL\"),\n",
        "    (\"Costa Rica\", \"CRC\"),\n",
        "    (\"Cuba\", \"CUB\"),\n",
        "    (\"Dominican Republic\", \"DOM\"),\n",
        "    (\"Dominica\", \"DMA\"),\n",
        "    (\"El Salvador\", \"ESA\"),\n",
        "    (\"Ecuador\", \"ECU\"),\n",
        "    (\"Grenada\", \"GRN\"),\n",
        "    (\"Guatemala\", \"GUA\"),\n",
        "    (\"Guyana\", \"GUY\"),\n",
        "    (\"Haiti\", \"HAI\"),\n",
        "    (\"Honduras\", \"HON\"),\n",
        "    (\"Jamaica\", \"JAM\"),\n",
        "    (\"Mexico\", \"MEX\"),\n",
        "    (\"Nicaragua\", \"NCA\"),\n",
        "    (\"Panama\", \"PAN\"),\n",
        "    (\"Paraguay\", \"PAR\"),\n",
        "    (\"Peru\", \"PER\"),\n",
        "    (\"Puerto Rico\", \"PUR\"),\n",
        "    (\"Saint Kitts and Nevis\", \"SKN\"),\n",
        "    (\"Saint Lucia\", \"LCA\"),\n",
        "    (\"St. Vincent and the Grenadines\", \"VIN\"),\n",
        "    (\"Suriname\", \"SUR\"),\n",
        "    (\"Trinidad and Tobago\", \"TTO\"),\n",
        "    (\"United States\", \"USA\"),\n",
        "    (\"Uruguay\", \"URU\"),\n",
        "    (\"Venezuela\", \"VEN\"),\n",
        "    (\"Virgin Islands, British\", \"IVB\"),\n",
        "    (\"United States Virgin Islands\", \"ISV\"),\n",
        "\n",
        "    # Asia\n",
        "    (\"Afghanistan\", \"AFG\"),\n",
        "    (\"Bahrain\", \"BRN\"),\n",
        "    (\"Bangladesh\", \"BAN\"),\n",
        "    (\"Bhutan\", \"BHU\"),\n",
        "    (\"Brunei Darussalam\", \"BRU\"),\n",
        "    (\"Cambodia\", \"CAM\"),\n",
        "    (\"China\", \"CHN\"),\n",
        "    (\"Republic of Korea\", \"KOR\"),\n",
        "    (\"Hong Kong, China\", \"HKG\"),\n",
        "    (\"India\", \"IND\"),\n",
        "    (\"Indonesia\", \"INA\"),\n",
        "    (\"Islamic Republic of Iran\", \"IRI\"),\n",
        "    (\"Iraq\", \"IRQ\"),\n",
        "    (\"Japan\", \"JPN\"),\n",
        "    (\"Jordan\", \"JOR\"),\n",
        "    (\"Kazakhstan\", \"KAZ\"),\n",
        "    (\"Kyrgyzstan\", \"KGZ\"),\n",
        "    (\"Kuwait\", \"KUW\"),\n",
        "    (\"Lao People’s Democratic Republic\", \"LAO\"),\n",
        "    (\"Lebanon\", \"LBN\"),\n",
        "    (\"Malaysia\", \"MAS\"),\n",
        "    (\"Maldives\", \"MDV\"),\n",
        "    (\"Mongolia\", \"MGL\"),\n",
        "    (\"Myanmar\", \"MYA\"),\n",
        "    (\"Nepal\", \"NEP\"),\n",
        "    (\"Oman\", \"OMA\"),\n",
        "    (\"Pakistan\", \"PAK\"),\n",
        "    (\"Palestine\", \"PLE\"),\n",
        "    (\"Philippines\", \"PHI\"),\n",
        "    (\"Qatar\", \"QAT\"),\n",
        "    (\"Democratic People’s Republic of Korea\", \"PRK\"),\n",
        "    (\"Saudi Arabia\", \"KSA\"),\n",
        "    (\"Singapore\", \"SGP\"),\n",
        "    (\"Sri Lanka\", \"SRI\"),\n",
        "    (\"Syrian Arab Republic\", \"SYR\"),\n",
        "    (\"Tajikistan\", \"TJK\"),\n",
        "    (\"Chinese Taipei\", \"TPE\"),\n",
        "    (\"Thailand\", \"THA\"),\n",
        "    (\"East Timor\", \"TLS\"),\n",
        "    (\"Turkmenistan\", \"TKM\"),\n",
        "    (\"United Arab Emirates\", \"UAE\"),\n",
        "    (\"Uzbekistan\", \"UZB\"),\n",
        "    (\"Vietnam\", \"VIE\"),\n",
        "    (\"Yemen\", \"YEM\"),\n",
        "\n",
        "    # Europe\n",
        "    (\"Albania\", \"ALB\"),\n",
        "    (\"Andorra\", \"AND\"),\n",
        "    (\"Armenia\", \"ARM\"),\n",
        "    (\"Austria\", \"AUT\"),\n",
        "    (\"Azerbaijan\", \"AZE\"),\n",
        "    (\"Belgium\", \"BEL\"),\n",
        "    (\"Bosnia and Herzegovina\", \"BIH\"),\n",
        "    (\"Bulgaria\", \"BUL\"),\n",
        "    (\"Cyprus\", \"CYP\"),\n",
        "    (\"Croatia\", \"CRO\"),\n",
        "    (\"Czechia\", \"CZE\"),\n",
        "    (\"Denmark\", \"DEN\"),\n",
        "    (\"Spain\", \"ESP\"),\n",
        "    (\"Estonia\", \"EST\"),\n",
        "    (\"Finland\", \"FIN\"),\n",
        "    (\"France\", \"FRA\"),\n",
        "    (\"Georgia\", \"GEO\"),\n",
        "    (\"Germany\", \"GER\"),\n",
        "    (\"Great Britain\", \"GBR\"),\n",
        "    (\"Greece\", \"GRE\"),\n",
        "    (\"Hungary\", \"HUN\"),\n",
        "    (\"Ireland\", \"IRL\"),\n",
        "    (\"Iceland\", \"ISL\"),\n",
        "    (\"Israel\", \"ISR\"),\n",
        "    (\"Italy\", \"ITA\"),\n",
        "    (\"Kosovo\", \"KOS\"),\n",
        "    (\"Latvia\", \"LAT\"),\n",
        "    (\"Liechtenstein\", \"LIE\"),\n",
        "    (\"Lithuania\", \"LTU\"),\n",
        "    (\"Luxembourg\", \"LIE\"),\n",
        "    (\"North Macedonia\", \"MKD\"),\n",
        "    (\"Malta\", \"MLT\"),\n",
        "    (\"Republic of Moldova\", \"MDA\"),\n",
        "    (\"Monaco\", \"MON\"),\n",
        "    (\"Montenegro\", \"MNE\"),\n",
        "    (\"Netherlands\", \"NED\"),\n",
        "    (\"Norway\", \"NOR\"),\n",
        "    (\"Poland\", \"POL\"),\n",
        "    (\"Portugal\", \"POR\"),\n",
        "    (\"Romania\", \"ROU\"),\n",
        "    (\"San Marino\", \"SMR\"),\n",
        "    (\"Serbia\", \"SRB\"),\n",
        "    (\"Slovakia\", \"SVK\"),\n",
        "    (\"Slovenia\", \"SLO\"),\n",
        "    (\"Sweden\", \"SWE\"),\n",
        "    (\"Switzerland\", \"SUI\"),\n",
        "    (\"Türkiye\", \"TUR\"),\n",
        "    (\"Ukraine\", \"UKR\"),\n",
        "\n",
        "    # Oceania\n",
        "    (\"American Samoa\", \"ASA\"),\n",
        "    (\"Australia\", \"AUS\"),\n",
        "    (\"Cook Islands\", \"COK\"),\n",
        "    (\"Fiji\", \"FIJ\"),\n",
        "    (\"Guam\", \"GUM\"),\n",
        "    (\"Kiribati\", \"KIR\"),\n",
        "    (\"Marshall Islands\", \"MHL\"),\n",
        "    (\"Federated States of Micronesia\", \"FSM\"),\n",
        "    (\"Nauru\", \"NRU\"),\n",
        "    (\"New Zealand\", \"NZL\"),\n",
        "    (\"Palau\", \"PLW\"),\n",
        "    (\"Papua New Guinea\", \"PNG\"),\n",
        "    (\"Solomon Islands\", \"SOL\"),\n",
        "    (\"Samoa\", \"SAM\"),\n",
        "    (\"Tonga\", \"TGA\"),\n",
        "    (\"Tuvalu\", \"TUV\"),\n",
        "    (\"Vanuatu\", \"VAN\")\n",
        "]\n"
      ],
      "metadata": {
        "id": "B4UGleX19Fup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorry *insert name of your elementary school teacher here*, we'll be using Wikipedia!"
      ],
      "metadata": {
        "id": "HQBl4BqKb2LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Wikipedia API\n",
        "wiki_wiki = wikipediaapi.Wikipedia(user_agent='My_Olympic_Data_Bot/1.0 (randomemail@gmail.com)')\n",
        "\n",
        "#Initialize transformer pipeline for text feature extraction\n",
        "nlp = pipeline(\"feature-extraction\", model=\"bert-base-uncased\", device=device)"
      ],
      "metadata": {
        "id": "an4Zh5VE5L1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers are super cool. Let's see what a transformer can fetch and tell us about different countries from Wikipedia."
      ],
      "metadata": {
        "id": "Hm1CZlaocCyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text features from Wikipedia\n",
        "def get_country_features(country_name):\n",
        "    page = wiki_wiki.page(country_name)\n",
        "\n",
        "    if not page.exists():\n",
        "        print(f\"Wikipedia page not found for: {country_name}\")\n",
        "        return None\n",
        "\n",
        "    # Extract summary text\n",
        "    summary_text = page.summary\n",
        "\n",
        "    # Truncate the summary text to fit within the BERT model's limit\n",
        "    # BERT models typically have a maximum sequence length of 512 tokens\n",
        "    tokens = summary_text.split()\n",
        "    tokens = tokens[:512] # Truncate to 512 tokens\n",
        "\n",
        "    # Use the transformer model to extract features\n",
        "    features = nlp(summary_text, truncation=True, max_length=512 )\n",
        "\n",
        "    # Aggregating features (e.g., mean across the tokens)\n",
        "    aggregated_features = [sum(x)/len(x) for x in zip(*features[0])]\n",
        "\n",
        "    return aggregated_features"
      ],
      "metadata": {
        "id": "1EZIPGGa5LzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compile features for all countries\n",
        "def compile_country_features():\n",
        "    all_country_features = {}\n",
        "\n",
        "    for country_name, NOC in participating_countries:\n",
        "        features = get_country_features(country_name)\n",
        "        if features:\n",
        "            all_country_features[NOC] = features\n",
        "\n",
        "    return all_country_features\n",
        "\n",
        "# Compile features for all countries\n",
        "country_features = compile_country_features()\n",
        "\n",
        "# Display sample features\n",
        "print(f\"Sample features for United States: {country_features.get('United States')}\")"
      ],
      "metadata": {
        "id": "KNPmtEXk_A0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is why we need NOC's. So we can use our data easily and in a uniform way. Look:"
      ],
      "metadata": {
        "id": "9QVg31BtcRLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "U S A! U S A!"
      ],
      "metadata": {
        "id": "qLp5M5Bqcgsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sample features for United States: {country_features.get('USA')}\")"
      ],
      "metadata": {
        "id": "M3fmQDUaxFti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should be getting long vectors of numbers, which are our bert-generated features. If you're getting None here, something is wrong."
      ],
      "metadata": {
        "id": "Vlvbn8iAcjBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sample features for China: {country_features.get('CHN')}\")"
      ],
      "metadata": {
        "id": "eG0MEosptRpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, now let's look at some data and start preprocessing it. Paris2024 is a Summer Olympics, so we'll only be looking at Summer editions."
      ],
      "metadata": {
        "id": "1G2tr29Wcvyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "historical_medal_tally_path = '/data/Olympic_Games_Medal_Tally.csv'\n",
        "paris_2024_medal_tally_path = '/data/Paris_2024_Medal_Table.csv'\n",
        "\n",
        "# Load the CSV files into dataframes\n",
        "historical_medal_tally = pd.read_csv(historical_medal_tally_path)\n",
        "historical_medal_tally.rename(columns={'country_noc': 'country_code'}, inplace=True)\n",
        "\n",
        "# Filter the data for Summer Olympics only\n",
        "historical_medal_tally['edition'] = historical_medal_tally['edition'].str.replace(' Olympics', '')\n",
        "historical_medal_tally[['Year', 'Season']] = historical_medal_tally['edition'].str.split(' ', expand=True)\n",
        "historical_medal_tally = historical_medal_tally.drop(columns=['year'])\n",
        "historical_medal_tally_summer = historical_medal_tally[historical_medal_tally['Season'] == 'Summer']\n",
        "paris_2024_medal_tally = pd.read_csv(paris_2024_medal_tally_path)\n",
        "\n",
        "participating_countries_df = pd.DataFrame(participating_countries, columns=['country', 'country_code'])\n",
        "\n",
        "\n",
        "historical_medal_tally_summer\n"
      ],
      "metadata": {
        "id": "G0p2iA8lK1H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not all countries have won medals yet, and yet we can't completely disregard them- there might be surprises!"
      ],
      "metadata": {
        "id": "UBjg6Bqmc_Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to add missing countries with 0 medals\n",
        "def add_missing_countries(medal_tally_df, left_on, right_on):\n",
        "    # Merge the medal tally with participating countries\n",
        "    merged_df = pd.merge(participating_countries_df, medal_tally_df, left_on=left_on, right_on=right_on, how='left')\n",
        "\n",
        "    # Fill NaN values (for countries with no medals) with 0\n",
        "    merged_df.fillna(0, inplace=True)\n",
        "\n",
        "    return merged_df"
      ],
      "metadata": {
        "id": "OHdZJf4oD7FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll try two test cases: First we'll filter out countries which haven't won medals recently. This is mainly in order to disregard former countries like East Germany, Soviet Russia and such, which were IMMENSE Olympic powerhouses but no longer exist. We don't want them biasing our data..."
      ],
      "metadata": {
        "id": "TosoBnjLdMwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case 1: country filtering - predicting only for countries which have won medals in recent Olympics\n",
        "historical_medal_tally = add_missing_countries(historical_medal_tally_summer, ['country_code'], ['country_code'])\n",
        "paris_2024_medal_tally = add_missing_countries(paris_2024_medal_tally, ['country_code'], ['country_code'])\n",
        "historical_medal_tally = historical_medal_tally.drop(columns=['country_y']).rename(columns={'country_x': 'Country'})\n",
        "\n",
        "\n",
        "historical_medal_tally['Year'] = historical_medal_tally['Year'].astype(int) # Convert 'year' column to integer type\n",
        "historical_medal_tally"
      ],
      "metadata": {
        "id": "7ofQu3YXDq8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our second case doesn't do that, but rather looks at all the countries participating in Paris2024."
      ],
      "metadata": {
        "id": "QWUky6cddm51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Test case 2: without country filtering - predicting for all participating countries\n",
        "historical_medal_tally_case_2 = historical_medal_tally\n",
        "paris_2024_medal_tally_case_2 = paris_2024_medal_tally\n",
        "historical_medal_tally_case_2"
      ],
      "metadata": {
        "id": "asA-vUqwfvSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we think about it, a lot has changed in the world in over a century that the Olympics have been going on. East Germany used to be a powerhouse and no longer exists. The same goes for Yugoslavia and the USSR. Countries have been banned or boycotted, a refugee team and a neutral team were established, and more. In addition, many countries have made great development both in sports and in general.\n",
        "With that in mind, it might be inaccurate to predict based on over 100 years of data.\n",
        "Let's filter out data prior to 1992, because things have been more stable since.\n",
        "\n",
        "We'll have two test cases: One to review only the countries which have won at least 6 medals since 1992, and another to review all participating countries."
      ],
      "metadata": {
        "id": "Bb03JLH1Zu9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test case 1: Keep only countries which have won at least 8 medals since Barcelona 1992 for relevance\n",
        "historical_medal_tally_filtered = historical_medal_tally[historical_medal_tally['Year'] >= 1992]\n",
        "medals_by_country = historical_medal_tally_filtered.groupby('country_code')['total'].sum()\n",
        "countries_with_at_least_6_medals = medals_by_country[medals_by_country >= 6].index\n",
        "countries_with_at_least_6_medals_df = pd.DataFrame(countries_with_at_least_6_medals)\n",
        "medals = pd.DataFrame(medals_by_country)\n",
        "historical_medal_tally_refined = historical_medal_tally_filtered[historical_medal_tally_filtered['country_code'].isin(countries_with_at_least_8_medals)]\n",
        "paris_2024_medal_tally_refined = paris_2024_medal_tally[paris_2024_medal_tally['country_code'].isin(countries_with_at_least_6_medals)]\n",
        "historical_medal_tally_df = pd.DataFrame(historical_medal_tally_refined).reset_index(drop=True)\n",
        "paris_2024_medal_tally_df = pd.DataFrame(paris_2024_medal_tally_refined).reset_index(drop=True)\n",
        "\n",
        "\n",
        "#Test case 2:\n",
        "historical_medal_tally_case_2 = historical_medal_tally[historical_medal_tally['Year'] >= 1992]\n",
        "historical_medal_tally_case_2_df = pd.DataFrame(historical_medal_tally_case_2).reset_index(drop=True)\n",
        "paris_2024_medal_tally_case_2_refined = paris_2024_medal_tally_case_2\n",
        "paris_2024_medal_tally_case_2_df = pd.DataFrame(paris_2024_medal_tally_case_2_refined).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "OgjQpWj3DOOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the countries which won medals recently(at least 8 since Sydney2000)"
      ],
      "metadata": {
        "id": "doZy9zwSdxDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "countries_with_at_least_6_medals_df"
      ],
      "metadata": {
        "id": "5vA7MTyzZT39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feel free to view the dataframes"
      ],
      "metadata": {
        "id": "wp1jjMGHd4Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "historical_medal_tally_df"
      ],
      "metadata": {
        "id": "owGkLTlrepaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paris_2024_medal_tally_df"
      ],
      "metadata": {
        "id": "3cbLDPi8erJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We promise, this is as much data processing as we'll be doing today. Pretty straightforward"
      ],
      "metadata": {
        "id": "dnbHWhNgeBRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing steps to standardize country codes and names for merging\n",
        "\n",
        "# Standardize column names for easier merging\n",
        "historical_medal_tally_df.rename(columns={'total': 'Total', 'gold': 'Gold', 'silver': 'Silver', 'bronze': 'Bronze'}, inplace=True)\n",
        "historical_medal_tally_case_2_df.rename(columns={'total': 'Total', 'gold': 'Gold', 'silver': 'Silver', 'bronze': 'Bronze'}, inplace=True)\n",
        "paris_2024_medal_tally_df.rename(columns={'Gold Medal': 'Gold', 'Silver Medal': 'Silver', 'Bronze Medal': 'Bronze'}, inplace=True)\n",
        "paris_2024_medal_tally_case_2_df.rename(columns={'Gold Medal': 'Gold', 'Silver Medal': 'Silver', 'Bronze Medal': 'Bronze'}, inplace=True)\n",
        "historical_medal_tally_df\n",
        "\n"
      ],
      "metadata": {
        "id": "XI34ShR4Oj8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's only keep the NOC, year and medal tallies. EVerything else isn't so important."
      ],
      "metadata": {
        "id": "I-NXv8VfeOCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant columns for merging: ['country_code', 'Total']\n",
        "historical_medal_tally_relevant = historical_medal_tally_df[['country_code', 'Year', 'Total', 'Gold', 'Silver', 'Bronze']]\n",
        "historical_medal_tally_relevant_case_2 = historical_medal_tally_case_2_df[['country_code', 'Year', 'Total', 'Gold', 'Silver', 'Bronze']]"
      ],
      "metadata": {
        "id": "x9PABg6iOuyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical_medal_tally_relevant"
      ],
      "metadata": {
        "id": "FZmCBbnZOwOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical_medal_tally_relevant_case_2"
      ],
      "metadata": {
        "id": "P3F0jv5XkFql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick look at the countries before we do the learning. We can see that the second test case has many more countries because we didn't filter anything out."
      ],
      "metadata": {
        "id": "NdlIX7xFeX7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paris_2024_medal_tally_relevant = paris_2024_medal_tally_df[['country_code', 'Total', 'Gold', 'Silver', 'Bronze']]\n",
        "paris_2024_medal_tally_relevant_case_2 = paris_2024_medal_tally_case_2_df[['country_code', 'Total', 'Gold', 'Silver', 'Bronze']]\n",
        "paris_2024_unique_codes = paris_2024_medal_tally_relevant['country_code'].unique()\n",
        "historical_medal_tally_unique_codes = historical_medal_tally_relevant['country_code'].unique()\n",
        "paris_2024_unique_codes_case_2 = paris_2024_medal_tally_relevant_case_2['country_code'].unique()\n",
        "historical_medal_tally_unique_codes_case_2 = historical_medal_tally_relevant_case_2['country_code'].unique()\n",
        "\n",
        "\n",
        "paris_2024_unique_codes, paris_2024_unique_codes_case_2"
      ],
      "metadata": {
        "id": "1DVl0UIhLkt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, this is sequential, so just run everything one by one. The DF views are mainly for debugging. Can you find China?"
      ],
      "metadata": {
        "id": "zl1f3xEBetCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing to merge BERT features with medal tally data\n",
        "# We already have the country_names from BERT feature extraction which corresponds to the country names\n",
        "# We will match these with country codes from the medal tally data\n",
        "\n",
        "# First, let's create a DataFrame for the BERT features with corresponding country codes\n",
        "bert_feature_df = pd.DataFrame.from_dict(country_features, orient='index')\n",
        "num_features = len(next(iter(country_features.values())))\n",
        "bert_feature_df.columns = [f'feature_{i}' for i in range(num_features)]\n",
        "bert_feature_df['country_code'] = bert_feature_df.index\n",
        "\n",
        "bert_feature_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Drop rows with missing country codes (countries that are not in the medal tally data)\n",
        "bert_feature_df.dropna(subset=['country_code'], inplace=True)\n",
        "\n",
        "# Now, let's merge the BERT features with both historical and Paris 2024 medal data\n",
        "# Case 1\n",
        "historical_data_with_features = pd.merge(historical_medal_tally_relevant, bert_feature_df, on='country_code', how='inner')\n",
        "paris_2024_data_with_features = pd.merge(paris_2024_medal_tally_relevant, bert_feature_df, on='country_code', how='inner')\n",
        "# Case 2\n",
        "historical_data_with_features_case_2 = pd.merge(historical_medal_tally_relevant_case_2, bert_feature_df, on='country_code', how='inner')\n",
        "paris_2024_data_with_features_case_2 = pd.merge(paris_2024_medal_tally_relevant_case_2, bert_feature_df, on='country_code', how='inner')\n",
        "\n",
        "historical_data_with_features.shape, paris_2024_data_with_features.shape, historical_data_with_features_case_2.shape, paris_2024_data_with_features_case_2.shape\n"
      ],
      "metadata": {
        "id": "XD0aoikwLzyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical_data_with_features = pd.DataFrame(historical_data_with_features)\n",
        "historical_data_with_features"
      ],
      "metadata": {
        "id": "EWGAeK5gOGOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical_data_with_features_case_2 = pd.DataFrame(historical_data_with_features_case_2)\n",
        "historical_data_with_features_case_2"
      ],
      "metadata": {
        "id": "IAHUcKixmbX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paris_2024_data_with_features = pd.DataFrame(paris_2024_data_with_features)\n",
        "paris_2024_data_with_features"
      ],
      "metadata": {
        "id": "0EgpQXYQOLdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paris_2024_data_with_features_case_2 = pd.DataFrame(paris_2024_data_with_features_case_2)\n",
        "paris_2024_data_with_features_case_2"
      ],
      "metadata": {
        "id": "7f3-CQdNmi6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#THE MAIN EVENT\n",
        "\n",
        "Ok, we made it so far.\n",
        "Let's scale the data and it into train and validation sets. We'll use the ACTUAL Paris results as a test set(should be ready before our presentation). How cool is that?"
      ],
      "metadata": {
        "id": "lAURs063D8V2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler1 = StandardScaler()\n",
        "scaler2 = StandardScaler()\n",
        "# Splitting features and target (Total medals)\n",
        "X_train = historical_data_with_features.drop(columns=['Total', 'Gold', 'Silver', 'Bronze', 'country_code'])\n",
        "X_train_2 = historical_data_with_features_case_2.drop(columns=['Total', 'Gold', 'Silver', 'Bronze', 'country_code'])\n",
        "\n",
        "X_train = X_train.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
        "X_train_2 = X_train_2.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
        "\n",
        "X_train_scaled = scaler1.fit_transform(X_train)\n",
        "X_train_tensor_scaled = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "X_train_scaled_2 = scaler2.fit_transform(X_train_2)\n",
        "X_train_tensor_scaled_2 = torch.tensor(X_train_scaled_2, dtype=torch.float32).to(device)\n",
        "\n",
        "y_train = historical_data_with_features[['Total', 'Gold', 'Silver', 'Bronze']]\n",
        "y_train_2 = historical_data_with_features_case_2[['Total', 'Gold', 'Silver', 'Bronze']]\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
        "y_train_tensor_2 = torch.tensor(y_train_2.values, dtype=torch.float32).to(device)\n",
        "\n",
        "paris_2024_data_with_features_sorted = paris_2024_data_with_features.sort_values(by='Gold', ascending=False)\n",
        "paris_2024_data_with_features_sorted_2 = paris_2024_data_with_features_case_2.sort_values(by='Gold', ascending=False)\n",
        "\n",
        "X_test = paris_2024_data_with_features_sorted.drop(columns=['Total', 'Gold', 'Silver', 'Bronze', 'country_code'])\n",
        "X_test_2 = paris_2024_data_with_features_sorted_2.drop(columns=['Total', 'Gold', 'Silver', 'Bronze', 'country_code'])\n",
        "test_countries = paris_2024_data_with_features_sorted['country_code']\n",
        "test_countries_2 = paris_2024_data_with_features_sorted_2['country_code']\n",
        "\n",
        "# Add a constant 'Year' column to X_test with value 2024\n",
        "X_test.insert(0, 'Year', 2024)\n",
        "X_test_2.insert(0, 'Year', 2024)\n",
        "#Scale and transform\n",
        "X_test_scaled = scaler1.transform(X_test)  # Use the same scaler fitted on training data\n",
        "X_test_tensor_scaled = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "X_test_scaled_2 = scaler2.transform(X_test_2)  # Use the same scaler fitted on training data\n",
        "X_test_tensor_scaled_2 = torch.tensor(X_test_scaled_2, dtype=torch.float32).to(device)\n",
        "\n",
        "y_test = paris_2024_data_with_features_sorted[['Total', 'Gold', 'Silver', 'Bronze']]\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
        "\n",
        "y_test_2 = paris_2024_data_with_features_sorted_2[['Total', 'Gold', 'Silver', 'Bronze']]\n",
        "y_test_tensor_2 = torch.tensor(y_test_2.values, dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rIhczUj9N6FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAINING\n",
        "\n",
        "We'll use Optuna in order to tuna Hyperparameters and find the best combo. Then we'll train our network and see the results. It's as simple as that."
      ],
      "metadata": {
        "id": "1Ggtw-21fTt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "# Splitting train and validation data\n",
        "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train_tensor_scaled, y_train_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameter search space\n",
        "    n_units_1 = trial.suggest_int('n_units_1', 256, 1024)\n",
        "    n_units_2 = trial.suggest_int('n_units_2', 128, 512)\n",
        "    n_units_3 = trial.suggest_int('n_units_3', 64, 256)\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3)\n",
        "\n",
        "    # Building the model with trial hyperparameters\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(X_train_sub.shape[1], n_units_1),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(n_units_1, n_units_2),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(n_units_2, n_units_3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_units_3, 4)  # Output layer for regression\n",
        "    ).to(device)  # Move the model to the GPU\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(20):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train_sub).to(device)\n",
        "        loss = criterion(outputs.squeeze(), y_train_sub)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on validation data\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val).to(device)\n",
        "        val_outputs = torch.round(val_outputs)  # Round the predictions to the nearest integer\n",
        "        val_mae = {}\n",
        "        val_accuracy = {}\n",
        "\n",
        "        for i, medal_type in enumerate(['Total', 'Gold', 'Silver', 'Bronze']):\n",
        "          mae = torch.mean(torch.abs(val_outputs[:,i] - y_val[:,i])).item()\n",
        "          val_mae[medal_type] = mae\n",
        "          correct = torch.sum(torch.abs(val_outputs[:,i] - y_val[:,i]) <= torch.tensor(tolerance_biases[i]).to(device)*y_val[:,i])\n",
        "          accuracy = correct.item() / len(y_val) * 100\n",
        "          val_accuracy[medal_type] = accuracy\n",
        "          val_loss = criterion(val_outputs[:,i], y_val[:,i])\n",
        "        print(f\"Validation Loss: {val_loss} ; Validation Accuracy: {accuracy}%\")\n",
        "\n",
        "    return sum(val_mae.values())  # Return the validation MAE as a Python numbe\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "print(\"Best hyperparameters: \", best_params)\n",
        "\n",
        "# Build and evaluate the model with the best hyperparameters\n",
        "n_units_1 = best_params['n_units_1']\n",
        "n_units_2 = best_params['n_units_2']\n",
        "n_units_3 = best_params['n_units_3']\n",
        "dropout_rate = best_params['dropout_rate']\n",
        "learning_rate = best_params['learning_rate']\n",
        "tolerance = 0.2\n",
        "tolerance_biases = [6.0, 2.0, 2.0, 2.0]\n",
        "\n",
        "    # Building the model with trial hyperparameters\n",
        "best_model = nn.Sequential(\n",
        "        nn.Linear(X_train_tensor_scaled.shape[1], n_units_1),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(n_units_1, n_units_2),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(n_units_2, n_units_3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_units_3, 4)  # Output layer for regression\n",
        "    ).to(device)  # Move the model to the GPU\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(best_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train with the entire training data and evaluate on the test set\n",
        "losses = []\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = best_model(X_train_tensor_scaled).to(device)\n",
        "    loss = criterion(outputs.squeeze(), y_train_tensor)\n",
        "    loss.backward()\n",
        "    losses.append(loss.item())\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "    optimizer.step()\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    test_mae = {}\n",
        "    test_accuracy = {}\n",
        "    test_outputs = best_model(X_test_tensor_scaled).to(device)\n",
        "    test_outputs = torch.round(test_outputs)  # Round the predictions to the nearest integer\n",
        "    for i, medal_type in enumerate(['Total', 'Gold', 'Silver', 'Bronze']):\n",
        "      test_loss = criterion(test_outputs[:,i], y_test_tensor[:,i])\n",
        "      correct = torch.sum(torch.abs(test_outputs[:,i] - y_test_tensor[:,i]) <= torch.max(tolerance*y_test_tensor[:,i], torch.tensor(tolerance_biases[i]).to(device)))\n",
        "      accuracy = correct.item() / len(y_test) * 100\n",
        "      test_accuracy[medal_type] = accuracy\n",
        "      mae = torch.mean(torch.abs(test_outputs[:,i] - y_test_tensor[:,i])).item()  # Calculate MAE\n",
        "      test_mae[medal_type] = mae\n",
        "\n",
        "\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "print(f\"Test Loss: {test_loss} ; Test Accuracy: {test_accuracy}%\")\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs for Test Case 1')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xgBn-ZPiTqLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what the results are. We already have predictions for each medal separately and total medals in the previous cell. Pretty accurate, right? Wait till you see when happens in the second test case."
      ],
      "metadata": {
        "id": "nc9RoVqLfneJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medal_manual_sum = torch.sum(test_outputs[:,1:], dim=1)\n",
        "sum_correct = torch.sum(torch.abs(medal_manual_sum - y_test_tensor[:,0]) <= torch.max(tolerance*y_test_tensor[:,0], torch.tensor(6.0).to(device)))\n",
        "sum_accuracy = sum_correct.item() / len(y_test) * 100\n",
        "\n",
        "print(f\"Test Accuracy for Manual Medal Total: {sum_accuracy}%\")"
      ],
      "metadata": {
        "id": "P-Dg1isPajqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Olympic medal table is ranked by and order of precedence: Gold, then Silver, then Bronze. We'll apply this precedence to our accuracy as well.\n",
        "medal_importance_weight = [0.4, 0.3, 0.2, 0.1]\n",
        "medal_table_accuracy_case_1 = test_accuracy['Gold']*medal_importance_weight[0] + test_accuracy['Silver']*medal_importance_weight[1] + test_accuracy['Bronze']*medal_importance_weight[2] + test_accuracy['Total']*medal_importance_weight[3]\n",
        "print(f\"Test Accuracy for Medal Table with Medal Precedence: {medal_table_accuracy_case_1}%\")"
      ],
      "metadata": {
        "id": "rg4Ma_NwkHZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No let's see the predicted table!"
      ],
      "metadata": {
        "id": "qo45EJ8cgCDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_countries = np.array(test_countries)  # Convert to a numpy array if it's not already\n",
        "\n",
        "# Create a DataFrame from the test predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'Country': test_countries,\n",
        "    'Predicted Gold': test_outputs[:, 1].cpu().numpy(),\n",
        "    'Predicted Silver': test_outputs[:, 2].cpu().numpy(),\n",
        "    'Predicted Bronze': test_outputs[:, 3].cpu().numpy(),\n",
        "    'Predicted Total': test_outputs[:, 0].cpu().numpy(),\n",
        "    'Total Predicted': medal_manual_sum.cpu().numpy()\n",
        "})\n",
        "\n",
        "predictions_df = predictions_df.sort_values(by=['Predicted Gold', 'Predicted Silver', 'Predicted Bronze'], ascending=False).reset_index(drop=True)\n",
        "predictions_df.index += 1\n",
        "predictions_df\n"
      ],
      "metadata": {
        "id": "iv3WE7gEudHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And for reference, the actual table(added at the end of the Olympics):"
      ],
      "metadata": {
        "id": "q0tIoEX_gEsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual_df = pd.DataFrame({\n",
        "    'Country': test_countries,\n",
        "    'Actual Gold': y_test['Gold'].values,\n",
        "    'Actual Silver': y_test['Silver'].values,\n",
        "    'Actual Bronze': y_test['Bronze'].values,\n",
        "    'Actual Total': y_test['Total'].values\n",
        "})\n",
        "actual_df = actual_df.sort_values(by=['Actual Gold', 'Actual Silver', 'Actual Bronze'], ascending=False).reset_index(drop=True)\n",
        "actual_df.index += 1\n",
        "actual_df"
      ],
      "metadata": {
        "id": "e5wCEEQ43UxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, now for the second test case. Here we didn't filter anything out, just looked at all the participating countries in Paris."
      ],
      "metadata": {
        "id": "NgcyJK3hgMB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case 2:\n",
        "\n",
        "# Splitting train and validation data\n",
        "X_train_sub_2, X_val_2, y_train_sub_2, y_val_2 = train_test_split(X_train_tensor_scaled_2, y_train_tensor_2, test_size=0.2, random_state=42)\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameter search space\n",
        "    n_units_1 = trial.suggest_int('n_units_1', 256, 1024)\n",
        "    n_units_2 = trial.suggest_int('n_units_2', 128, 512)\n",
        "    n_units_3 = trial.suggest_int('n_units_3', 64, 256)\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3)\n",
        "\n",
        "    # Building the model with trial hyperparameters\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(X_train_sub.shape[1], n_units_1),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(n_units_1, n_units_2),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(n_units_2, n_units_3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_units_3, 4)  # Output layer for regression\n",
        "    ).to(device)  # Move the model to the GPU\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(20):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train_sub_2).to(device)\n",
        "        loss = criterion(outputs.squeeze(), y_train_sub_2)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on validation data\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val_2).to(device)\n",
        "        val_outputs = torch.round(val_outputs)  # Round the predictions to the nearest integer\n",
        "        val_mae = {}\n",
        "        val_accuracy = {}\n",
        "        tolerance = 0.2\n",
        "        tolerance_biases = [6.0, 2.0, 2.0, 2.0]\n",
        "        for i, medal_type in enumerate(['Total', 'Gold', 'Silver', 'Bronze']):\n",
        "          mae = torch.mean(torch.abs(val_outputs[:,i] - y_val_2[:,i])).item()\n",
        "          val_mae[medal_type] = mae\n",
        "          correct = torch.sum(torch.abs(val_outputs[:,i] - y_val_2[:,i]) <= torch.tensor(tolerance_biases[i]).to(device)*y_val_2[:,i])\n",
        "          accuracy = correct.item() / len(y_val_2) * 100\n",
        "          val_accuracy[medal_type] = accuracy\n",
        "          val_loss = criterion(val_outputs[:,i], y_val_2[:,i])\n",
        "        print(f\"Validation Loss: {val_loss} ; Validation Accuracy: {accuracy}%\")\n",
        "\n",
        "    return sum(val_mae.values())  # Return the validation MAE as a Python numbe\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = study.best_params\n",
        "print(\"Best hyperparameters: \", best_params)\n",
        "\n",
        "# Build and evaluate the model with the best hyperparameters\n",
        "n_units_1 = best_params['n_units_1']\n",
        "n_units_2 = best_params['n_units_2']\n",
        "n_units_3 = best_params['n_units_3']\n",
        "dropout_rate = best_params['dropout_rate']\n",
        "learning_rate = best_params['learning_rate']\n",
        "tolerance = 0.2\n",
        "tolerance_biases = [6.0, 2.0, 2.0, 2.0]\n",
        "\n",
        "    # Building the model with trial hyperparameters\n",
        "best_model = nn.Sequential(\n",
        "        nn.Linear(X_train_tensor_scaled_2.shape[1], n_units_1),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(n_units_1, n_units_2),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(n_units_2, n_units_3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_units_3, 4)  # Output layer for regression\n",
        "    ).to(device)  # Move the model to the GPU\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(best_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train with the entire training data and evaluate on the test set\n",
        "losses = []\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = best_model(X_train_tensor_scaled_2).to(device)\n",
        "    loss = criterion(outputs.squeeze(), y_train_tensor_2)\n",
        "    loss.backward()\n",
        "    losses.append(loss.item())\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "    optimizer.step()\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "with torch.no_grad():\n",
        "    test_mae = {}\n",
        "    test_accuracy_2 = {}\n",
        "    test_outputs_2 = best_model(X_test_tensor_scaled_2).to(device)\n",
        "    test_outputs_2 = torch.round(test_outputs_2)  # Round the predictions to the nearest integer\n",
        "    for i, medal_type in enumerate(['Total', 'Gold', 'Silver', 'Bronze']):\n",
        "      test_loss = criterion(test_outputs_2[:,i], y_test_tensor_2[:,i])\n",
        "      correct = torch.sum(torch.abs(test_outputs_2[:,i] - y_test_tensor_2[:,i]) <= torch.max(tolerance*y_test_tensor_2[:,i], torch.tensor(tolerance_biases[i]).to(device)))\n",
        "      accuracy = correct.item() / len(y_test_2) * 100\n",
        "      test_accuracy_2[medal_type] = accuracy\n",
        "      mae = torch.mean(torch.abs(test_outputs_2[:,i] - y_test_tensor_2[:,i])).item()  # Calculate MAE\n",
        "      test_mae[medal_type] = mae\n",
        "\n",
        "\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "print(f\"Test Loss: {test_loss} ; Test Accuracy: {test_accuracy_2}%\")\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs for Test Case 2')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6ZXY3Sx9nmiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow, that's crazy! Let's sum them up:"
      ],
      "metadata": {
        "id": "pz5PyhBHgT0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medal_manual_sum_2 = torch.sum(test_outputs_2[:,1:], dim=1)\n",
        "sum_correct = torch.sum(torch.abs(medal_manual_sum_2 - y_test_tensor_2[:,0]) <= torch.max(tolerance*y_test_tensor_2[:,0], torch.tensor(6.0).to(device)))\n",
        "sum_accuracy_2 = sum_correct.item() / len(y_test_2) * 100\n",
        "\n",
        "print(f\"Test Accuracy for Manual Medal Total in Test Case 2: {sum_accuracy_2}%\")"
      ],
      "metadata": {
        "id": "rllG-3hHonsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Olympic medal table is ranked by and order of precedence: Gold, then Silver, then Bronze. We'll apply this precedence to our accuracy as well.\n",
        "medal_importance_weight = [0.4, 0.3, 0.2, 0.1]\n",
        "medal_table_accuracy_case_2 = test_accuracy_2['Gold']*medal_importance_weight[0] + test_accuracy_2['Silver']*medal_importance_weight[1] + test_accuracy_2['Bronze']*medal_importance_weight[2] + test_accuracy_2['Total']*medal_importance_weight[3]\n",
        "print(f\"Test Accuracy for Medal Table with Medal Precedence: {medal_table_accuracy_case_2}%\")"
      ],
      "metadata": {
        "id": "OaZ10KQ4irO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And for the medal table..."
      ],
      "metadata": {
        "id": "NCy_ZJsZgYdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_countries_2 = np.array(test_countries_2) #Convert to np array to put in a dataframe\n",
        "\n",
        "# Create a DataFrame from the test predictions\n",
        "predictions_case_2_df = pd.DataFrame({\n",
        "    'Country': test_countries_2,\n",
        "    'Predicted Gold': test_outputs_2[:, 1].cpu().numpy(), #Move to cpu to use numpy\n",
        "    'Predicted Silver': test_outputs_2[:, 2].cpu().numpy(),\n",
        "    'Predicted Bronze': test_outputs_2[:, 3].cpu().numpy(),\n",
        "    'Predicted Total': test_outputs_2[:, 0].cpu().numpy(),\n",
        "    'Total Predicted': medal_manual_sum_2.cpu().numpy()\n",
        "})\n",
        "\n",
        "predictions_case_2_df = predictions_case_2_df.sort_values(by=['Predicted Gold', 'Predicted Silver', 'Predicted Bronze'], ascending=False).reset_index(drop=True)\n",
        "predictions_case_2_df.index += 1\n",
        "predictions_case_2_df"
      ],
      "metadata": {
        "id": "thYObqK5pXoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare to the actual results:"
      ],
      "metadata": {
        "id": "EiHxNisjgcht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual_df_2 = pd.DataFrame({\n",
        "    'Country': test_countries_2,\n",
        "    'Actual Gold': y_test_2['Gold'].values,\n",
        "    'Actual Silver': y_test_2['Silver'].values,\n",
        "    'Actual Bronze': y_test_2['Bronze'].values,\n",
        "    'Actual Total': y_test_2['Total'].values,\n",
        "})\n",
        "\n",
        "actual_df_2 = actual_df_2.sort_values(by=['Actual Gold', 'Actual Silver', 'Actual Bronze'], ascending=False).reset_index(drop=True)\n",
        "actual_df_2.index += 1\n",
        "actual_df_2"
      ],
      "metadata": {
        "id": "-2v7bwk9poAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And that's it for today. See you in 2028(or 2026 but then you'll have to go up and swap \"summer\" out for \"winter\")!"
      ],
      "metadata": {
        "id": "cgk-suQtghr3"
      }
    }
  ]
}